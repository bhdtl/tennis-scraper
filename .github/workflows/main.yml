name: Neural Scout Syncon v2.0

on:
  schedule:
    - cron: '*/30 * * * *'  # Alle 30 Minuten
  workflow_dispatch:        # Manueller Trigger erlaubt

# Best Practice: Rechte auf das Nötigste beschränken
permissions:
  contents: read

jobs:
  scrape:
    name: Run Scraper Job
    runs-on: ubuntu-latest
    timeout-minutes: 60     # WICHTIG: Stoppt den Job nach 60 Min, falls der Scraper hängt (spart Action-Minuten)

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'      # PERFORMANCE: Caches pip packages automatically

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright & System Deps
        run: |
          playwright install chromium --with-deps

      - name: Run Scraper
        env:
          # SECURITY: Ensure these secrets are set in GitHub Repo Settings
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}             # <--- NEU: Der Schlüssel für Groq
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}             # Public Anon Key usually
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }} # Admin Key for bypass RLS
        run: |
          python scraper.py
